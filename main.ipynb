{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## Install requirements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==1.1.0 from https://download.pytorch.org/whl/cu100/torch-1.1.0-cp36-cp36m-linux_x86_64.whl\n",
      "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu100/torch-1.1.0-cp36-cp36m-linux_x86_64.whl (770.7MB)\n",
      "\u001b[K     |████████████████████████████████| 770.7MB 77kB/s  eta 0:00:013    |██                              | 47.9MB 10.7MB/s eta 0:01:08     |████████████████                | 386.7MB 687kB/s eta 0:09:19     |████████████████████▎           | 487.2MB 12.3MB/s eta 0:00:24     |██████████████████████▎         | 537.7MB 63.9MB/s eta 0:00:04███████████████████████▋      | 617.7MB 11.5MB/s eta 0:00:14\n",
      "\u001b[?25hRequirement already satisfied: numpy in ./.venv3/lib/python3.6/site-packages (from torch==1.1.0) (1.16.4)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.1.0\n",
      "Collecting torchvision==0.3.0 from https://download.pytorch.org/whl/cu100/torchvision-0.3.0-cp36-cp36m-linux_x86_64.whl\n",
      "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu100/torchvision-0.3.0-cp36-cp36m-linux_x86_64.whl (2.6MB)\n",
      "\u001b[K     |████████████████████████████████| 2.6MB 403kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in ./.venv3/lib/python3.6/site-packages (from torchvision==0.3.0) (1.12.0)\n",
      "Collecting pillow>=4.1.1 (from torchvision==0.3.0)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/41/db6dec65ddbc176a59b89485e8cc136a433ed9c6397b6bfe2cd38412051e/Pillow-6.1.0-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1MB 5.1MB/s eta 0:00:01     |███████████▎                    | 727kB 5.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in ./.venv3/lib/python3.6/site-packages (from torchvision==0.3.0) (1.16.4)\n",
      "Requirement already satisfied: torch>=1.1.0 in ./.venv3/lib/python3.6/site-packages (from torchvision==0.3.0) (1.1.0)\n",
      "Installing collected packages: pillow, torchvision\n",
      "Successfully installed pillow-6.1.0 torchvision-0.3.0\n",
      "Collecting tensorboardX\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a2/57/2f0a46538295b8e7f09625da6dd24c23f9d0d7ef119ca1c33528660130d5/tensorboardX-1.7-py2.py3-none-any.whl (238kB)\n",
      "\u001b[K     |████████████████████████████████| 245kB 9.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in ./.venv3/lib/python3.6/site-packages (from tensorboardX) (1.16.4)\n",
      "Collecting protobuf>=3.2.0 (from tensorboardX)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/fb/29de8d08967f0cce1bb10b39846d836b0f3bf6776ddc36aed7c73498ca7e/protobuf-3.8.0-cp36-cp36m-manylinux1_x86_64.whl (1.2MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2MB 9.4MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in ./.venv3/lib/python3.6/site-packages (from tensorboardX) (1.12.0)\n",
      "Requirement already satisfied: setuptools in ./.venv3/lib/python3.6/site-packages (from protobuf>=3.2.0->tensorboardX) (41.0.1)\n",
      "Installing collected packages: protobuf, tensorboardX\n",
      "Successfully installed protobuf-3.8.0 tensorboardX-1.7\n"
     ]
    }
   ],
   "source": [
    "!pip install https://download.pytorch.org/whl/cu100/torch-1.1.0-cp36-cp36m-linux_x86_64.whl\n",
    "!pip install https://download.pytorch.org/whl/cu100/torchvision-0.3.0-cp36-cp36m-linux_x86_64.whl\n",
    "!pip install tensorboardX\n",
    "!pip install scikit-learn\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tensorboardX import SummaryWriter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leyendo /data/jeperez/COCO-2014-spanish/train/train_images_names.txt\n",
      "leyendo /data/jeperez/COCO-2014-spanish/train/train_images_vectors.bin\n",
      "20000 vectores de largo 2048\n",
      "leyendo /data/jeperez/COCO-2014-spanish/train/train_captions.txt\n",
      "leyendo /data/jeperez/COCO-2014-spanish/test_A/test_A_images_names.txt\n",
      "leyendo /data/jeperez/COCO-2014-spanish/test_A/test_A_images_vectors.bin\n",
      "1000 vectores de largo 2048\n",
      "leyendo /data/jeperez/COCO-2014-spanish/test_A/test_A_captions.txt\n",
      "COCO_train2014_000000000086.jpg: Un hombre en un una vieja bicicleta de moda en el bosque\n",
      "COCO_train2014_000000000086.jpg: Un hombre montado en una bicicleta de motor a través de un bosque.\n",
      "COCO_train2014_000000000086.jpg: Un hombre sentado en una motocicleta en el bosque.\n",
      "COCO_train2014_000000000086.jpg: Una persona que mira hacia abajo en algo mientras está sentado en una bicicleta.\n",
      "COCO_train2014_000000000086.jpg: Una persona joven está en una vieja bicicleta muy adornado.\n",
      "COCO_train2014_000000000077.jpg: un grupo de adolescentes saltando una rampa en sus monopatines\n",
      "COCO_train2014_000000000077.jpg: Una imagen de lapso de tiempo de un individuo en una tabla de skate.\n",
      "COCO_train2014_000000000077.jpg: Un hombre joven que monta un patín en el aire.\n",
      "COCO_train2014_000000000077.jpg: Grupo de niños que realizan truco patín en rampa con la pintada en ella\n",
      "COCO_train2014_000000000077.jpg: algunos patinadores masculinos están haciendo algunos trucos y graffiti\n"
     ]
    }
   ],
   "source": [
    "from data import get_loader, load_coco_files\n",
    "\n",
    "phases = ['train', 'test_A']\n",
    "batch_size = {'train': 200, 'test_A': 1000}\n",
    "shuffle = {'train': True, 'test_A': False}\n",
    "num_workers = {'train': 4, 'test_A': 1}\n",
    "pin_memory = {'train': True, 'test_A': False}\n",
    "\n",
    "loaders = {}\n",
    "coco_images_names = {}\n",
    "for phase in phases:\n",
    "    folder_dir = os.path.join('/data/jeperez/COCO-2014-spanish/', phase)\n",
    "    file_names = os.path.join(folder_dir, '{}_images_names.txt'.format(phase))\n",
    "    file_vectors = os.path.join(folder_dir, '{}_images_vectors.bin'.format(phase))\n",
    "    file_captions = os.path.join(folder_dir, '{}_captions.txt'.format(phase))\n",
    "    coco_images_names[phase], coco_visual_feats, coco_captions = load_coco_files(file_names, file_vectors, file_captions, 2048)\n",
    "    loaders[phase] = get_loader(coco_images_names[phase], coco_visual_feats, coco_captions, batch_size[phase], shuffle[phase], \n",
    "                              num_workers[phase], pin_memory[phase])\n",
    "    \n",
    "    if phase == 'train':\n",
    "        train_names, train_texts = zip(*coco_captions)\n",
    "\n",
    "for s in ['{}: {}'.format(n, s) for n,s in zip(train_names[0:10], train_texts[0:10])]:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defines the divice to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "from utils import get_freer_gpu\n",
    "\n",
    "device = 'gpu'\n",
    "\n",
    "if device == 'gpu' and torch.cuda.is_available():\n",
    "    freer_gpu_id = get_freer_gpu()\n",
    "    device = torch.device('cuda:{}'.format(freer_gpu_id))\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## Seleccionar el modelo para representación de los textos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "descriptor size: 291\n"
     ]
    }
   ],
   "source": [
    "text_descriptor_name = 'tf-idf'\n",
    "\n",
    "if text_descriptor_name == 'bow':\n",
    "    from text_descriptors.bow import TextDescriptor\n",
    "    text_descriptor = TextDescriptor(type='bow', texts=train_texts, lowecase=False, ngram_range=(1,1), \n",
    "                                     max_df=.8, min_df=.01)\n",
    "elif text_descriptor_name == 'tf-idf':\n",
    "    from text_descriptors.bow import TextDescriptor\n",
    "    text_descriptor = TextDescriptor(type='tf-idf', texts=train_texts, lowecase=False, ngram_range=(1,3), \n",
    "                                     max_df=.8, min_df=.01)\n",
    "elif text_descriptor_name == 'lsa':\n",
    "    from text_descriptors.lsa import LSADescriptor\n",
    "    text_descriptor = LSADescriptor(type='tf-idf', texts=train_texts, lowecase=False, ngram_range=(1,3), \n",
    "                                    max_df=.8, min_df=.01, n_components=100)\n",
    "elif text_descriptor_name == 'embedding':\n",
    "    from text_descriptors.embedding import WordEmbedding\n",
    "    from vocabulary import Vocabulary\n",
    "    vocab = Vocabulary(max_df=1, min_df=0)\n",
    "    vocab.add_sentences(train_texts)\n",
    "    vocab.add_words(['<unk>', '<pad>'])\n",
    "    text_descriptor = WordEmbedding(num_embeddings=len(vocab), embedding_dim=300)\n",
    "    text_descriptor.to(device)\n",
    "else:\n",
    "    raise 'unknown descriptor {}'.format(text_descriptor_name)\n",
    "\n",
    "print('descriptor size: {}'.format(text_descriptor.out_size))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## Initialize the Regressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% \n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (fc1): Linear(in_features=291, out_features=4096, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (drop_1): Dropout(p=0.2)\n",
       "  (fc2): Linear(in_features=4096, out_features=2048, bias=True)\n",
       "  (relu2): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from text_encoders.regressor import MLP, RNN\n",
    "\n",
    "regression_model_name = 'mlp' # ['mlp', 'rnn']\n",
    "\n",
    "if regression_model_name == 'mlp':\n",
    "    regression_model = MLP(in_size=text_descriptor.out_size, h_size=4096, out_size=2048)\n",
    "elif text_descriptor_name == 'embedding' and regression_model_name == 'rnn':\n",
    "    regression_model = RNN(in_size=text_descriptor.out_size, h_size=2048, num_layers=1, bidirectional=False, device=device)\n",
    "else:\n",
    "    raise 'unknown configuration: {} + {}'.format(text_descriptor_name, regression_model_name)\n",
    "    \n",
    "regression_model.to(device)\n",
    "regression_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "## loss function and optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSELoss()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "## optimizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "encoder_optimizer = optim.SGD(regression_model.parameters(), lr=0.01)\n",
    "print(encoder_optimizer)\n",
    "\n",
    "if text_descriptor_name == 'embedding':\n",
    "    embedding_optimizer = optim.Adam(text_descriptor.parameters(), lr=0.001)\n",
    "    print(embedding_optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "# initialize tensorboard logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorboardX.writer.SummaryWriter at 0x7f4bf63e0470>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_name = '{}-{}'.format(text_descriptor_name, regression_model_name)\n",
    "datetime_str = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "writer = SummaryWriter(logdir=os.path.join('./log/runs/', '{}-{}'.format(exp_name, datetime_str)))\n",
    "writer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "# Train Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "phase: train\n",
      "[0/500]\n",
      "[100/500]\n",
      "[200/500]\n",
      "[300/500]\n",
      "[400/500]\n",
      "loss: 0.001314208984375\n",
      "phase: test_A\n",
      "[0/5]\n",
      "loss: 0.139220130443573\n",
      "(1000, 2048)\n",
      "torch.Size([5000, 2048])\n",
      "epoch: 1\n",
      "phase: train\n",
      "[0/500]\n",
      "[100/500]\n",
      "[200/500]\n",
      "[300/500]\n",
      "[400/500]\n",
      "loss: 0.0012340683937072754\n",
      "phase: test_A\n",
      "[0/5]\n",
      "loss: 0.1269922971725464\n",
      "(1000, 2048)\n",
      "torch.Size([5000, 2048])\n",
      "epoch: 2\n",
      "phase: train\n",
      "[0/500]\n",
      "[100/500]\n",
      "[200/500]\n",
      "[300/500]\n",
      "[400/500]\n",
      "loss: 0.001212866187095642\n",
      "phase: test_A\n",
      "[0/5]\n",
      "loss: 0.12327580451965332\n",
      "(1000, 2048)\n",
      "torch.Size([5000, 2048])\n",
      "epoch: 3\n",
      "phase: train\n",
      "[0/500]\n",
      "[100/500]\n",
      "[200/500]\n",
      "[300/500]\n",
      "[400/500]\n",
      "loss: 0.0011872925758361816\n",
      "phase: test_A\n",
      "[0/5]\n",
      "loss: 0.12226094007492065\n",
      "(1000, 2048)\n",
      "torch.Size([5000, 2048])\n",
      "epoch: 4\n",
      "phase: train\n",
      "[0/500]\n",
      "[100/500]\n",
      "[200/500]\n",
      "[300/500]\n",
      "[400/500]\n",
      "loss: 0.0012205474376678466\n",
      "phase: test_A\n",
      "[0/5]\n",
      "loss: 0.12330120801925659\n",
      "(1000, 2048)\n",
      "torch.Size([5000, 2048])\n",
      "epoch: 5\n",
      "phase: train\n",
      "[0/500]\n",
      "[100/500]\n",
      "[200/500]\n",
      "[300/500]\n",
      "[400/500]\n",
      "loss: 0.0011808987855911255\n",
      "phase: test_A\n",
      "[0/5]\n",
      "loss: 0.1242000937461853\n",
      "(1000, 2048)\n",
      "torch.Size([5000, 2048])\n",
      "epoch: 6\n",
      "phase: train\n",
      "[0/500]\n",
      "[100/500]\n",
      "[200/500]\n",
      "[300/500]\n",
      "[400/500]\n",
      "loss: 0.0011719479560852052\n",
      "phase: test_A\n",
      "[0/5]\n",
      "loss: 0.12466644048690796\n",
      "(1000, 2048)\n",
      "torch.Size([5000, 2048])\n",
      "epoch: 7\n",
      "phase: train\n",
      "[0/500]\n",
      "[100/500]\n",
      "[200/500]\n",
      "[300/500]\n",
      "[400/500]\n",
      "loss: 0.0012099475860595703\n",
      "phase: test_A\n",
      "[0/5]\n",
      "loss: 0.1256001830101013\n",
      "(1000, 2048)\n",
      "torch.Size([5000, 2048])\n",
      "epoch: 8\n",
      "phase: train\n",
      "[0/500]\n",
      "[100/500]\n",
      "[200/500]\n",
      "[300/500]\n",
      "[400/500]\n",
      "loss: 0.001192067265510559\n",
      "phase: test_A\n",
      "[0/5]\n",
      "loss: 0.12594339847564698\n",
      "(1000, 2048)\n",
      "torch.Size([5000, 2048])\n",
      "epoch: 9\n",
      "phase: train\n",
      "[0/500]\n",
      "[100/500]\n",
      "[200/500]\n",
      "[300/500]\n",
      "[400/500]\n",
      "loss: 0.0011983729600906373\n",
      "phase: test_A\n",
      "[0/5]\n",
      "loss: 0.12597229480743408\n",
      "(1000, 2048)\n",
      "torch.Size([5000, 2048])\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for e in range(epochs):\n",
    "    print('epoch: {}'.format(e))\n",
    "    for phase in phases:\n",
    "        print('phase: {}'.format(phase))\n",
    "        \n",
    "        regression_model.train()\n",
    "        if regression_model_name == 'rnn':\n",
    "            text_descriptor.train()\n",
    "        \n",
    "        names = []\n",
    "        encoded_vectors = []\n",
    "        loss_count = 0\n",
    "        for i, (images_names, visual_feats, captions) in enumerate(loaders[phase]):\n",
    "#             print('{} - {}'.format(images_names[0], captions[0]))\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                if regression_model_name == 'mlp':\n",
    "                    if text_descriptor_name == 'embedding':\n",
    "                        idx_texts = vocab(captions, 20)\n",
    "                        idx_texts = torch.LongTensor(idx_texts).to(device)\n",
    "                        descriptors = text_descriptor(idx_texts)\n",
    "                        descriptors = torch.mean(descriptors, dim=1)\n",
    "                    else:\n",
    "                        descriptors = text_descriptor.transform(captions)\n",
    "                        descriptors = torch.FloatTensor(descriptors.toarray()).to(device)\n",
    "                    encodes = regression_model(descriptors)\n",
    "                elif regression_model_name == 'rnn':\n",
    "                    idx_texts = vocab(captions, 20)\n",
    "                    idx_texts = torch.LongTensor(idx_texts).to(device)\n",
    "                    descriptors = text_descriptor(idx_texts)\n",
    "                    encodes = regression_model(descriptors)\n",
    "            \n",
    "                # Evaluate the loss function\n",
    "                loss = criterion(encodes, visual_feats.to(device))\n",
    "    \n",
    "            if phase == 'train':\n",
    "                loss.backward()\n",
    "                encoder_optimizer.step()\n",
    "                if regression_model_name == 'rnn':\n",
    "                    embedding_optimizer.step()\n",
    "            else:\n",
    "                encoded_vectors.append(encodes)\n",
    "                names += images_names\n",
    "            \n",
    "            loss_count += loss.item()\n",
    "            writer.add_scalar('{}-loss'.format(phase), loss, e * len(loaders[phase]) + i)\n",
    "            if i%100 == 0:\n",
    "                print('[{}/{}]'.format(i, len(loaders[phase])))\n",
    "            \n",
    "        print('loss: {}'.format(loss.item()/len(loaders[phase])))\n",
    "    \n",
    "        # compute measures\n",
    "        metric='l2'\n",
    "        k=5\n",
    "        if phase != 'train':\n",
    "            regression_model.eval()\n",
    "            if regression_model_name == 'rnn':\n",
    "                text_descriptor.eval()\n",
    "                \n",
    "            encoded_vectors = torch.cat(encoded_vectors, dim=0)\n",
    "            coco_visual_feats = np.array(coco_visual_feats)\n",
    "            print(coco_visual_feats.shape)\n",
    "            print(encoded_vectors.size())\n",
    "            \n",
    "            avg_position = 0\n",
    "            recall_at_k = 0\n",
    "            mrr = 0\n",
    "            for i, feats_vec in enumerate(encoded_vectors.cpu().numpy()):\n",
    "                if metric == 'l2':\n",
    "                    dist = np.sqrt(np.sum((coco_visual_feats - feats_vec) ** 2, axis=1))\n",
    "                else:  # L1\n",
    "                    dist = np.sqrt(np.sum((coco_visual_feats - feats_vec), axis=1))\n",
    "                \n",
    "                sorted_idx = sorted(range(coco_visual_feats.shape[0]), key=lambda x: dist[x])\n",
    "                result_position = sorted_idx.index(coco_images_names[phase].index(names[i])) + 1\n",
    "                avg_position += result_position\n",
    "                recall_at_k += 1 if result_position <= k else 0\n",
    "                mrr += 1/result_position\n",
    "            writer.add_scalar('{}-avg_position'.format(phase), avg_position / len(encoded_vectors), e)\n",
    "            writer.add_scalar('{}-recall@{}'.format(phase, k), recall_at_k / len(encoded_vectors), e)\n",
    "            writer.add_scalar('{}-mrr'.format(phase), mrr / len(encoded_vectors), e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x7f6c79b6c518>,\n",
       " 'test_A': <torch.utils.data.dataloader.DataLoader at 0x7f6c7472b978>}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5000, 2048])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_vectors.size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "stem_cell": {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
