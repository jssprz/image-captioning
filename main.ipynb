{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Buscador de imágenes por descripción\n",
    "## Autores\n",
    "1. Jhonny Cerezo\n",
    "2. Jesús Pérez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Las redes neuronales son bien conocidas por problemas de clasificación, por ejemplo, se usan en la clasificación de dígitos escritos a mano, pero la pregunta es ¿será fructífero si los usamos para problemas de regresión?\n",
    "\n",
    "En este trabajo usaremos las redes neuronales para representar descripciones textuales de imágenes de COCO en el espacio de los descriptores visuales de las imágenes de 2048 dimenciones obtenidos mediante ResNet152. Con esto pretendemos realizar búsquedas de las imágenes relacionadas con una descripción."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## Requirements\n",
    "1. Python 3.6\n",
    "2. Pytorch 1.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!virtualenv -p python3 venv3\n",
    "!pip install -r requirements.txt\n",
    "# !pip install https://download.pytorch.org/whl/cu100/torch-1.1.0-cp36-cp36m-linux_x86_64.whl\n",
    "# !pip install https://download.pytorch.org/whl/cu100/torchvision-0.3.0-cp36-cp36m-linux_x86_64.whl\n",
    "# !pip install tensorboardX\n",
    "# !pip install scikit-learn\n",
    "# !pip install nltk\n",
    "# !pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tensorboardX import SummaryWriter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download pretrained word embeddings\n",
    "Para la representacion de las descipciones en Español de las imágenes se puede usar word-embeddings. Estos embeddings representan espacios donde ocurren propiedades interesantes entre las representaciones de cada una de las palabras. En nuestros experimentos word-embeddings preentrenados basados en: FastText y GloVe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./word-embeddings'):\n",
    "    os.mkdir('word-embeddings')\n",
    "    # download word-embeddings based on FastText\n",
    "    !cd word-embeddings && wget http://dcc.uchile.cl/~jperez/word-embeddings/fasttext-sbwc.vec.gz && gunzip fasttext-sbwc.vec.gz\n",
    "    # download word-embeddings based on GloVe\n",
    "    !cd word-embeddings && wget http://dcc.uchile.cl/~jperez/word-embeddings/glove-sbwc.i25.vec.gz && gunzip glove-sbwc.i25.vec.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "1. Download the COCO-2014-Spanish from https://drive.google.com/drive/folders/1RzGYR2uqMRS4WqX_wqIiI2Y_NdNAey1m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the dataset folder\n",
    "base_dir = '/data/jeperez/COCO-2014-spanish/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train\n",
      "leyendo /data/jeperez/COCO-2014-spanish/train/train_images_names.txt\n",
      "leyendo /data/jeperez/COCO-2014-spanish/train/train_images_vectors.bin\n",
      "20000 vectores de largo 2048\n",
      "leyendo /data/jeperez/COCO-2014-spanish/train/train_captions.txt\n",
      "\n",
      "test_A\n",
      "leyendo /data/jeperez/COCO-2014-spanish/test_A/test_A_images_names.txt\n",
      "leyendo /data/jeperez/COCO-2014-spanish/test_A/test_A_images_vectors.bin\n",
      "1000 vectores de largo 2048\n",
      "leyendo /data/jeperez/COCO-2014-spanish/test_A/test_A_captions.txt\n",
      "\n",
      "test_B\n",
      "leyendo /data/jeperez/COCO-2014-spanish/test_B/test_B_images_names.txt\n",
      "leyendo /data/jeperez/COCO-2014-spanish/test_B/test_B_images_vectors.bin\n",
      "1000 vectores de largo 2048\n",
      "leyendo /data/jeperez/COCO-2014-spanish/test_B/test_B_captions.txt\n",
      "\n",
      "test_C\n",
      "leyendo /data/jeperez/COCO-2014-spanish/test_C/test_C_images_names.txt\n",
      "leyendo /data/jeperez/COCO-2014-spanish/test_C/test_C_images_vectors.bin\n",
      "1000 vectores de largo 2048\n",
      "leyendo /data/jeperez/COCO-2014-spanish/test_C/test_C_captions.txt\n",
      "\n",
      "sample train data\n",
      "COCO_train2014_000000000086.jpg: Un hombre en un una vieja bicicleta de moda en el bosque\n",
      "COCO_train2014_000000000086.jpg: Un hombre montado en una bicicleta de motor a través de un bosque.\n",
      "COCO_train2014_000000000086.jpg: Un hombre sentado en una motocicleta en el bosque.\n",
      "COCO_train2014_000000000086.jpg: Una persona que mira hacia abajo en algo mientras está sentado en una bicicleta.\n",
      "COCO_train2014_000000000086.jpg: Una persona joven está en una vieja bicicleta muy adornado.\n",
      "COCO_train2014_000000000077.jpg: un grupo de adolescentes saltando una rampa en sus monopatines\n",
      "COCO_train2014_000000000077.jpg: Una imagen de lapso de tiempo de un individuo en una tabla de skate.\n",
      "COCO_train2014_000000000077.jpg: Un hombre joven que monta un patín en el aire.\n",
      "COCO_train2014_000000000077.jpg: Grupo de niños que realizan truco patín en rampa con la pintada en ella\n",
      "COCO_train2014_000000000077.jpg: algunos patinadores masculinos están haciendo algunos trucos y graffiti\n"
     ]
    }
   ],
   "source": [
    "from data import get_loader, load_coco_files\n",
    "\n",
    "phases = ['train', 'test_A', 'test_B', 'test_C']\n",
    "loaders, coco_images_names, coco_visual_feats, coco_captions = {}, {}, {}, {}\n",
    "for phase in phases:\n",
    "    print('\\n{}'.format(phase))\n",
    "    folder_dir = os.path.join(base_dir, phase)\n",
    "    file_names = os.path.join(folder_dir, '{}_images_names.txt'.format(phase))\n",
    "    file_vectors = os.path.join(folder_dir, '{}_images_vectors.bin'.format(phase))\n",
    "    file_captions = os.path.join(folder_dir, '{}_captions.txt'.format(phase))\n",
    "    coco_images_names[phase], coco_visual_feats[phase], coco_captions[phase] = load_coco_files(file_names, file_vectors, file_captions, 2048)\n",
    "            \n",
    "train_names, train_texts = zip(*coco_captions['train'])\n",
    "print('\\nsample train data')\n",
    "for s in ['{}: {}'.format(n, s) for n,s in zip(train_names[0:10], train_texts[0:10])]:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the divice to be used\n",
    "Seleccionamos el GPU con mayor espacio libre. Si desea correr los experimentos en CPU, cambie el valor de la variable 'device'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "from utils import get_freer_gpu\n",
    "\n",
    "device = 'gpu'\n",
    "\n",
    "if device == 'gpu' and torch.cuda.is_available():\n",
    "    freer_gpu_id = get_freer_gpu()\n",
    "    device = torch.device('cuda:{}'.format(freer_gpu_id))\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## Initialize Text Descriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "descriptor size: 300\n",
      "(2, 300)\n"
     ]
    }
   ],
   "source": [
    "text_descriptor_name = 'GloVe'\n",
    "\n",
    "if text_descriptor_name == 'tf-idf':\n",
    "    from text_descriptors.bow import TextDescriptor\n",
    "    text_descriptor = TextDescriptor(type='tf-idf', texts=train_texts, lowecase=False, ngram_range=(1,3), \n",
    "                                     max_df=.8, min_df=.01)\n",
    "# if text_descriptor_name == 'bow':\n",
    "#     from text_descriptors.bow import TextDescriptor\n",
    "#     text_descriptor = TextDescriptor(type='bow', texts=train_texts, lowecase=False, ngram_range=(1,1), \n",
    "#                                      max_df=.8, min_df=.01)\n",
    "# elif text_descriptor_name == 'lsa':\n",
    "#     from text_descriptors.lsa import LSADescriptor\n",
    "#     text_descriptor = LSADescriptor(type='tf-idf', texts=train_texts, lowecase=False, ngram_range=(1,3), \n",
    "#                                     max_df=.8, min_df=.01, n_components=100)\n",
    "elif text_descriptor_name == 'FastText':\n",
    "    from text_descriptors.embedding import WordEmbedding\n",
    "    from gensim.models.keyedvectors import KeyedVectors\n",
    "    wordvectors_file_vec = './word-embeddings/fasttext-sbwc.vec'\n",
    "    cantidad = 100000\n",
    "    wordvectors = KeyedVectors.load_word2vec_format(wordvectors_file_vec, limit=cantidad)\n",
    "    text_descriptor = WordEmbedding(wordvectors, embedding_dim=300)\n",
    "elif text_descriptor_name == 'GloVe':\n",
    "    from text_descriptors.embedding import WordEmbedding\n",
    "    from gensim.models.keyedvectors import KeyedVectors\n",
    "    wordvectors_file_vec = './word-embeddings/glove-sbwc.i25.vec'\n",
    "    cantidad = 100000\n",
    "    wordvectors = KeyedVectors.load_word2vec_format(wordvectors_file_vec, limit=cantidad)\n",
    "    text_descriptor = WordEmbedding(wordvectors, embedding_dim=300)\n",
    "# elif text_descriptor_name == 'my-embedding':\n",
    "#     from text_descriptors.embedding import WordEmbedding\n",
    "#     from vocabulary import Vocabulary\n",
    "#     vocab = Vocabulary(max_df=1, min_df=0)\n",
    "#     vocab.add_sentences(train_texts)\n",
    "#     vocab.add_words(['<unk>', '<pad>'])\n",
    "#     text_descriptor = WordEmbedding(num_embeddings=len(vocab), embedding_dim=300).to(device)\n",
    "else:\n",
    "    raise 'unknown descriptor {}'.format(text_descriptor_name)\n",
    "\n",
    "print('descriptor size: {}'.format(text_descriptor.out_size))\n",
    "print(text_descriptor.transform(['hermosa Habana', 'hola Cuba']).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = {'train': 200, 'test_A': 1000, 'test_B': 1000, 'test_C': 1000}\n",
    "shuffle = {'train': True, 'test_A': False, 'test_B': False, 'test_C': False}\n",
    "num_workers = {'train': 4, 'test_A': 1, 'test_B': 1, 'test_C': 1}\n",
    "pin_memory = {'train': True, 'test_A': False, 'test_B': False, 'test_C': False}\n",
    "\n",
    "loaders = {}\n",
    "for phase in phases:\n",
    "    phase_names, phase_captions = zip(*coco_captions[phase])\n",
    "    phase_captions_feats = text_descriptor.transform(phase_captions)\n",
    "    loaders[phase] = get_loader(coco_images_names[phase], coco_visual_feats[phase], coco_captions[phase], phase_captions_feats, batch_size[phase], shuffle[phase], \n",
    "                              num_workers[phase], pin_memory[phase])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## Initialize Regressor\n",
    "Para obtener las representaciones de las descripciones en el mismo espacio de los descriptores visuales usamos dos modelos distintos. \n",
    "1. Un percptrón multicapa (MLP) de una sola capa oculta de 4096 neuronas, una capa de dropout (con probabildad 0.2) y funcion de activación Relu. \n",
    "1. Una red recurrente con una capa GRU, donde el último estado interno (de 2048 dimenciones) es usado como la representación final de las descripciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% \n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (rnn): GRU(300, 2048, num_layers=2, batch_first=True, dropout=0.2)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from text_encoders.regressor import MLP, RNN\n",
    "\n",
    "regression_model_name = 'rnn' # ['mlp', 'rnn']\n",
    "\n",
    "if regression_model_name == 'mlp':\n",
    "    regression_model = MLP(in_size=text_descriptor.out_size, h_size=4096, out_size=2048)\n",
    "elif regression_model_name == 'rnn':\n",
    "    regression_model = RNN(in_size=text_descriptor.out_size, h_size=2048, num_layers=2, bidirectional=False, device=device)\n",
    "else:\n",
    "    raise 'unknown configuration: {} + {}'.format(text_descriptor_name, regression_model_name)\n",
    "\n",
    "regression_model.to(device)\n",
    "regression_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Define the Loss function\n",
    "La función de pérdida mas usada para problemas de regresión es el error cuadrático medio (MSE por sus siglas en inglés). MSE es el promedio de la pérdida al cuadrado de cada ejemplo. Para calcular el MSE, sumamos todas las pérdidas al cuadrado de los ejemplos individuales y, luego, lo dividimos por la cantidad de ejemplos.\n",
    "\n",
    "Otra funcion de perdida usada para los modelos de regresion es el error absoluto medio (MAE pos sus siglas en inglés). MAE es la suma de las diferencias absolutas entre nuestro objetivo y las variables pronosticadas. Por lo tanto, mide la magnitud promedio de los errores en un conjunto de predicciones, sin tener en cuenta sus direcciones. (Si consideramos las direcciones también, eso se llamaría Error de sesgo medio (MBE), que es una suma de residuos / errores).\n",
    "\n",
    "En resumen, el MAE es mejor para problemas simples. Como las redes neuronales se usan generalmente para problemas complejos, esta función rara vez se usa. En adición, los descriptores visuales de nuestro problema no posee un número muy alto de dimensiones (2048) y en estos casos, usar MSE no es una limitante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSELoss()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "#criterion = nn.L1Loss()\n",
    "#criterion = nn.SmoothL1Loss\n",
    "criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Define the Optimizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "encoder_optimizer = optim.SGD(regression_model.parameters(), lr=0.01)\n",
    "print(encoder_optimizer)\n",
    "\n",
    "# if text_descriptor_name == 'my-embedding':\n",
    "#     embedding_optimizer = optim.SGD(text_descriptor.parameters(), lr=0.01)\n",
    "#     print(embedding_optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Initialize tensorboard logger\n",
    "Los resultados del entrenamiento y la evaluación los mostramos por medio de la librería TensorboardX. Esta librería permite observar en tiempo real el desempeño de los modelos mediante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir=./log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados para cada uno de los experimentos (distintas configuraciones) se muestran en runs separados, nombrados con el formato: \n",
    "\n",
    "text_descriptor_name-regression_model_name-YmdHMS  \n",
    "\n",
    "ejemplo: FastText-mlp-20190710030120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorboardX.writer.SummaryWriter at 0x7f1e1d751588>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_name = '{}-{}'.format(text_descriptor_name, regression_model_name)\n",
    "datetime_str = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "writer = SummaryWriter(logdir=os.path.join('./log/runs/', '{}-{}'.format(exp_name, datetime_str)))\n",
    "writer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "# Train Regression\n",
    "A continuación entrenamos nuestro regresor y evaluamos el desempeño en cada uno de los tests de entrenamiento tras cada época. Junto con el cálculo de la pérdida en cada iteración, para la evaluación en cada época y cada test set computamos:\n",
    "1. Un histograma mostrando las posiciones en que queda la imagen asociada a cada una de las 5000 descripciones.\n",
    "2. La posición promedio\n",
    "3. Recall at 5\n",
    "4. MRR\n",
    "\n",
    "Todos los resultados se pueden ver en el tablero de tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "phase: train\n",
      "[0/500]\n",
      "[100/500]\n",
      "[200/500]\n",
      "[300/500]\n",
      "[400/500]\n",
      "loss: 0.0015056172609329223\n",
      "phase: test_A\n",
      "[0/5]\n",
      "loss: 0.15389121770858766\n",
      "phase: test_B\n",
      "[0/5]\n",
      "loss: 0.14595277309417726\n",
      "phase: test_C\n",
      "[0/5]\n",
      "loss: 0.14792768955230712\n",
      "epoch: 1\n",
      "phase: train\n",
      "[0/500]\n",
      "[100/500]\n",
      "[200/500]\n",
      "[300/500]\n",
      "[400/500]\n",
      "loss: 0.0014726345539093017\n",
      "phase: test_A\n",
      "[0/5]\n",
      "loss: 0.15047348737716676\n",
      "phase: test_B\n",
      "[0/5]\n",
      "loss: 0.1427962899208069\n",
      "phase: test_C\n",
      "[0/5]\n",
      "loss: 0.14458781480789185\n",
      "epoch: 2\n",
      "phase: train\n",
      "[0/500]\n"
     ]
    }
   ],
   "source": [
    "for e in range(20):  # epochs\n",
    "    print('epoch: {}'.format(e))\n",
    "    for phase in phases:\n",
    "        print('phase: {}'.format(phase))\n",
    "        \n",
    "        regression_model.train() if phase == 'train' else regression_model.eval()\n",
    "#         if text_descriptor_name == 'my-embedding':\n",
    "#             text_descriptor.train() if phase == 'train' else text_descriptor.eval()\n",
    "        \n",
    "        names = []\n",
    "        encoded_vectors = []\n",
    "        loss_count = 0\n",
    "        for i, (images_names, visual_feats, captions, captions_feats) in enumerate(loaders[phase]):\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "#                 if regression_model_name == 'mlp':\n",
    "#                     if text_descriptor_name == 'my-embedding':\n",
    "#                         idx_texts = vocab(captions, 20)\n",
    "#                         idx_texts = torch.LongTensor(idx_texts).to(device)\n",
    "#                         captions_feats = text_descriptor(idx_texts)\n",
    "#                         captions_feats = torch.mean(descriptors, dim=1)\n",
    "#                     else:\n",
    "#                         captions_feats = torch.FloatTensor(captions_feats.float()).to(device)\n",
    "#                 elif regression_model_name == 'rnn':\n",
    "#                     idx_texts = vocab(captions, 20)\n",
    "#                     idx_texts = torch.LongTensor(idx_texts).to(device)\n",
    "#                     captions_feats = text_descriptor(idx_texts)\n",
    "                \n",
    "                if regression_model_name == 'mlp':\n",
    "                    captions_feats = torch.FloatTensor(captions_feats.float()).to(device)\n",
    "                elif text_descriptor_name in ['FastText', 'GloVe']:\n",
    "                    captions_feats = torch.FloatTensor(text_descriptor.transform(captions, mode='words')).to(device)\n",
    "                encodes = regression_model(captions_feats)\n",
    "            \n",
    "                # Evaluate the loss function\n",
    "                loss = criterion(encodes, visual_feats.to(device))\n",
    "    \n",
    "            if phase == 'train':\n",
    "                loss.backward()\n",
    "                encoder_optimizer.step()\n",
    "#                 if text_descriptor_name == 'my-embedding':\n",
    "#                     embedding_optimizer.step()\n",
    "            else:\n",
    "                encoded_vectors.append(encodes)\n",
    "                names += images_names\n",
    "            \n",
    "            loss_count += loss.item()\n",
    "            writer.add_scalar('{}-loss'.format(phase), loss, e * len(loaders[phase]) + i)\n",
    "            if i%100 == 0:\n",
    "                print('[{}/{}]'.format(i, len(loaders[phase])))\n",
    "            \n",
    "        print('loss: {}'.format(loss.item()/len(loaders[phase])))\n",
    "    \n",
    "        # compute measures\n",
    "        metric,k = 'l2', 5\n",
    "        if phase != 'train':                \n",
    "            encoded_vectors = torch.cat(encoded_vectors, dim=0).cpu().numpy()\n",
    "            visual_feats = np.array(coco_visual_feats[phase])\n",
    "            \n",
    "            avg_position, recall_at_k, mrr, results = 0, 0, 0, []\n",
    "            for i, feats_vec in enumerate(encoded_vectors):\n",
    "                if metric == 'l2':\n",
    "                    dist = np.sqrt(np.sum((visual_feats - feats_vec) ** 2, axis=1))\n",
    "                else:  # L1\n",
    "                    dist = np.sqrt(np.sum((visual_feats - feats_vec), axis=1))\n",
    "                \n",
    "                sorted_idx = sorted(range(visual_feats.shape[0]), key=lambda x: dist[x])\n",
    "                result_position = sorted_idx.index(coco_images_names[phase].index(names[i])) + 1\n",
    "                results.append(result_position)\n",
    "                avg_position += result_position\n",
    "                recall_at_k += 1 if result_position <= k else 0\n",
    "                mrr += 1/result_position\n",
    "            writer.add_scalar('{}-avg_position'.format(phase), avg_position / len(encoded_vectors), e)\n",
    "            writer.add_scalar('{}-recall@{}'.format(phase, k), recall_at_k / len(encoded_vectors), e)\n",
    "            writer.add_scalar('{}-mrr'.format(phase), mrr / len(encoded_vectors), e)\n",
    "            writer.add_histogram('{}-hist'.format(phase), np.array(results), e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments and Results\n",
    "En la carpeta ./log/runs se encuentran los logs de los siguientes experimentos:\n",
    "1. FastText (centroid)  +  mlp\n",
    "2. GloVe    (centroid)  +  mlp\n",
    "3. tf-idf               +  mlp\n",
    "4. FastText             +  rnn\n",
    "5. GloVe                +  rnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclussions\n",
    "A partir de los resultados obtenidos podemos concluir que el modelo que presenta las mejores propiedades de generalización es ... Esto se debe a que el uso de ..... como modelo para representar las palabras aporta ... a la regresion. Mientras que .... no es capaz de .... A su vez, los modelos basados en MLP obtuvieron mejores resultados que las RNN. Esto es una concecuencia de que las descripciones de nuestro conjunto de entrenamiento no son lo suficientemente representativas de información asociada al orden en que se presentan las palabras dentro de las oraciones y su semántica."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "stem_cell": {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
