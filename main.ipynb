{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "import os\nimport datetime\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom tensorboardX import SummaryWriter\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": "from data import get_loader, load_coco_files\n\nphases \u003d [\u0027train\u0027, \u0027test_A\u0027]\nbatch_size \u003d {\u0027train\u0027: 200, \u0027test_A\u0027: 1000}\nshuffle \u003d {\u0027train\u0027: True, \u0027test_A\u0027: False}\nnum_workers \u003d {\u0027train\u0027: 4, \u0027test_A\u0027: 1}\npin_memory \u003d {\u0027train\u0027: True, \u0027test_A\u0027: False}\n\nloaders \u003d {}\nfor phase in phases:\n    folder_dir \u003d os.path.join(\u0027\u0027, phase)\n    file_names \u003d os.path.join(folder_dir, \u0027{}_images_names.txt\u0027.format(phase))\n    file_vectors \u003d os.path.join(folder_dir, \u0027{}_images_vectors.bin\u0027.format(phase))\n    file_captions \u003d os.path.join(folder_dir, \u0027{}_captions.txt\u0027.format(phase))\n    images_names, visual_feats, captions \u003d load_coco_files(file_names, file_vectors, file_captions, 2048)\n    loaders[phase] \u003d get_loader(images_names, visual_feats, captions, batch_size[phase], shuffle[phase], \n                              num_workers[phase], pin_memory[phase])\n    \n    if phase \u003d\u003d \u0027train\u0027:\n        names, train_texts \u003d zip(*captions)\n"
    },
    {
      "cell_type": "markdown",
      "source": "## Seleccionar el modelo para representaci√≥n de los textos\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "text_descriptor_name \u003d \u0027tf-idf\u0027\nassert text_descriptor_name in [\u0027bow\u0027, \u0027tf-idf\u0027, \u0027lsa\u0027]\n\nif text_descriptor_name \u003d\u003d \u0027bow\u0027:\n    from text_descriptors.bow import TextDescriptor\n    text_descriptor \u003d TextDescriptor(type\u003d\u0027bow\u0027, texts\u003dtrain_texts, lowecase\u003dFalse, ngrams_range\u003d(1,1), \n                                     max_df\u003d.8, min_df\u003d.01)\nelif text_descriptor_name \u003d\u003d \u0027tf-idf\u0027:\n    from text_descriptors.bow import TextDescriptor\n    text_descriptor \u003d TextDescriptor(type\u003d\u0027tf-idf\u0027, texts\u003dtrain_texts, lowecase\u003dFalse, ngrams_range\u003d(1,3), \n                                     max_df\u003d.8, min_df\u003d.01)\nelif text_descriptor_name \u003d\u003d \u0027lsa\u0027:\n    from text_descriptors.lsa import LSADescriptor\n    text_descriptor \u003d LSADescriptor(type\u003d\u0027tf-idf\u0027, texts\u003dtrain_texts, lowecase\u003dFalse, ngrams_range\u003d(1,3), \n                                    max_df\u003d.8, min_df\u003d.01, n_components\u003d100)\nelif text_descriptor_name \u003d\u003d \u0027embedding\u0027:\n    from text_descriptors.embedding import WordEmbedding\n    text_descriptor \u003d WordEmbedding(texts\u003dtrain_texts, lowecase\u003dFalse, ngrams_range\u003d(1,1), max_df\u003d.8, min_df\u003d.01)\n\nprint(text_descriptor.out_size)\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Defines Regression model\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "from text_encoders.regressor import MLP, RNN\n\nregression_model_name \u003d \u0027mlp\u0027 # [\u0027mlp\u0027, \u0027rnn\u0027]\n\nif regression_model_name \u003d\u003d \u0027mlp\u0027:\n    regression_model \u003d MLP(in_size\u003dtext_descriptor.out_size, h_size\u003d2048)\nelif regression_model_name \u003d\u003d \u0027rnn\u0027:\n    regression_model \u003d RNN(in_size\u003dtext_descriptor.out_size, h_size\u003d2048)\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% \n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## loss function and optimizer\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "criterion \u003d nn.MSELoss()\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## optimizers\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "encoder_optimizer \u003d optim.Adam(regression_model.parameters(), lr\u003d0.001)\nif regression_model_name \u003d\u003d \u0027rnn\u0027:\n    embedding_optimizer \u003d optim.Adam(text_descriptor.parameters(), lr\u003d0.001)\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "# initialize tensorboard logger",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "exp_name \u003d \u0027{}-{}\u0027.format(text_descriptor_name, regression_model_name)\ndatetime_str \u003d datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\nwriter \u003d SummaryWriter(log_dir\u003dos.path.join(\u0027./log/runs/\u0027, \u0027{}-{}\u0027.format(exp_name, datetime_str)))\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "# Train Regression",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "epochs \u003d 100\nfor e in range(epochs):\n    for phase in phases:\n        loss_count \u003d 0\n        for i, (images_names, visual_feats, captions) in enumerate(loaders[phase]):\n            with torch.set_grad_enabled(phase \u003d\u003d \u0027train\u0027):\n                if regression_model_name \u003d\u003d \u0027mlp\u0027:\n                    descriptors \u003d text_descriptor.transform(captions)\n                    encodes \u003d regression_model(descriptors)\n                elif regression_model_name \u003d\u003d \u0027rnn\u0027:\n                    idx_texts \u003d text_descriptor.word_to_idx(captions)\n                    descriptors \u003d text_descriptor(idx_texts)\n                    encodes \u003d regression_model(descriptors)\n            \n                # Evaluate the loss function\n                loss \u003d criterion(encodes, visual_feats)\n    \n            if phase \u003d\u003d \u0027train\u0027:\n                loss.backward()\n                encoder_optimizer.step()\n                if regression_model_name \u003d\u003d \u0027rnn\u0027:\n                    embedding_optimizer.step()\n            \n            loss_count +\u003d loss.item()\n            writer.add_scalar(\u0027{}-loss\u0027.format(phase), loss, e * len(loaders[phase]) + i)\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "stem_cell": {
      "cell_type": "raw",
      "source": "",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}